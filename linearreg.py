# -*- coding: utf-8 -*-
"""LinearReg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LwS0iUTc-tuwLr1YPCWpeMZ6NJdC6TLM
"""

from google.colab import drive

drive.mount("/content/gdrive")  
!pwd

# Commented out IPython magic to ensure Python compatibility.
#put your own path in google drive
# %cd "/content/gdrive/My Drive/IA/Class Activities"
!ls

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#
# Funciones para el cálculo del gradiente descendente
# 

def calcular_modelo(w,b,x):
    '''Retorna el valor w*x+b correspondiente al modelo lineal'''
    return w*x+b

def calcular_error(y,y_):
    '''Calcula el error cuadrático medio entre el dato original (y)
       y el dato generado por el modelo (y_)'''
    N = y.shape[0]
    error = np.sum((y-y_)**2)/N
    return error

def gradiente_descendente(w_, b_, alpha, x, y):
    '''Algoritmo del gradiente descendente para minimizar el error
       cuadrático medio'''
    N = x.shape[0]      # Cantidad de datos

    # Gradientes: derivadas de la función de error con respecto
    # a los parámetros "w" y "b"
    dw = -(2/N)*np.sum(x*(y-(w_*x+b_)))
    db = -(2/N)*np.sum(y-(w_*x+b_))

    # Actualizar los pesos usando la fórmula del gradiente descendente
    w = w_ - alpha*dw
    b = b_ - alpha*db

    return w, b

#
# Leer los datos en un DataFrame de Pandas
#
import pandas as pd
columns = ["Alcohol","Malic acid","Ash","Alcalinity of ash", "Magnesium", "Total phenols", "Flavanoids", "Nonflavanoid phenols", "Proanthocyanins", "Color intensity", "Hue", "OD280/OD315 of diluted wines", "Proline"]
datos = pd.read_csv('wine.data',names = columns)

datos.plot.scatter(x='Alcohol', y='Magnesium')
plt.xlabel('Alcohol')
plt.ylabel('Magnesium')
plt.show()

x = datos['Alcohol'].values
y = datos['Magnesium'].values


# Inicializar "w" y "b" aleatoriamente
w = np.random.randn(1)[0]
b = np.random.randn(1)[0]
alpha = 0.004
nits = 50000

# Entrenamiento
error = np.zeros((nits,1))
for i in range(nits):
    # Actualizar valor de los pesos usando el gradiente descendente
    [w, b] = gradiente_descendente(w,b,alpha,x,y)

    # Calcular el valor de la predicción
    y_ = calcular_modelo(w,b,x)

    # Actualizar el valor del error
    error[i] = calcular_error(y,y_)

    # Imprimir resultados cada 1000 epochs
    if (i+1)%1000 == 0:
        print("Epoch {}".format(i+1))
        print("    w: {:.1f}".format(w), " b: {:.1f}".format(b))
        print("    error: {}".format(error[i]))
        print("________________________________________________")

# Gráfica de SME vs iteraciones y de la regresión lineal resultante
plt.subplot(1,2,1)
plt.plot(range(nits),error)
plt.xlabel('Epoch')
plt.ylabel('SME')

y_regr = calcular_modelo(w,b,x)
plt.subplot(1,2,2)
plt.scatter(x,y)
plt.plot(x,y_regr,'r')
plt.xlabel('x')
plt.ylabel('y')
plt.show()

length= float(input('Enter the amount of alcohol ='))
MAGNESIO_AL = calcular_modelo(w,b,length)
print("A wine with an alcohol content of  {}".format(length), "  will have a magnesium content of {:.1f}".format(MAGNESIO_AL))